{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Users/yari/anaconda3/lib/python3.10/site-packages (18.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastavro in /Users/yari/anaconda3/lib/python3.10/site-packages (1.9.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install fastavro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Users/yari/anaconda3/lib/python3.10/site-packages (18.1.0)\n",
      "Requirement already satisfied: fastavro in /Users/yari/anaconda3/lib/python3.10/site-packages (1.9.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade pyarrow fastavro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.csv as csv\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.orc as orc\n",
    "from fastavro.schema import parse_schema\n",
    "from fastavro import writer\n",
    "import pyarrow.compute as pc\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pyarrow(file_path):\n",
    "    start_time = time.time()\n",
    "    table = csv.read_csv(file_path)\n",
    "    duration = time.time() - start_time\n",
    "    return table, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pyarrow_rename_columns(table):\n",
    "    start_time = time.time()\n",
    "    schema = table.schema\n",
    "    new_fields = [pa.field(f\"{col.name}_new\", col.type) for col in schema]\n",
    "    new_schema = pa.schema(new_fields)\n",
    "    table = table.rename_columns([col.name for col in new_schema])\n",
    "    duration = time.time() - start_time\n",
    "    return table, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_size(path):\n",
    "    return round(os.path.getsize(path) / (1024 * 1024), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pyarrow_csv(table, output_path):\n",
    "    start_time = time.time()\n",
    "    csv.write_csv(table, output_path)\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    file_size = get_file_size(output_path)\n",
    "\n",
    "    return duration, file_size\n",
    "\n",
    "def load_pyarrow_parquet(table, output_path):\n",
    "    start_time = time.time()\n",
    "    pq.write_table(table, output_path)\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    file_size = get_file_size(output_path)\n",
    "\n",
    "    return duration, file_size\n",
    "\n",
    "def load_pyarrow_orc(table, output_path):\n",
    "    start_time = time.time()\n",
    "    orc.write_table(table, output_path)\n",
    "    duration = time.time() - start_time\n",
    "\n",
    "    file_size = get_file_size(output_path)\n",
    "\n",
    "    return duration, file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yari/anaconda3/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process finished successfully!\n"
     ]
    }
   ],
   "source": [
    "datasets = ['transactions_data.csv', 'titanic.csv', 'reviews.csv', 'locations.csv']\n",
    "\n",
    "dim_datasets = []\n",
    "fact_metrics = []\n",
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "    primary_key = index + 1\n",
    "    path = dataset.split('.')[0]\n",
    "\n",
    "    table_raw, extract_time = extract_pyarrow(dataset)\n",
    "\n",
    "    table_transformed, transform_rename_columns_time = transform_pyarrow_rename_columns(table_raw)\n",
    "    \n",
    "    load_time_csv, file_size_csv = load_pyarrow_csv(table_transformed, f\"pyarrow_analysis/{path}.csv\")\n",
    "    load_time_parquet, file_size_parquet = load_pyarrow_parquet(table_transformed, f\"pyarrow_analysis/{path}.parquet\")\n",
    "    load_time_orc, file_size_orc = load_pyarrow_orc(table_transformed, f\"pyarrow_analysis/{path}.orc\")\n",
    "\n",
    "    dim_datasets.append({\n",
    "        \"id\": primary_key,\n",
    "        \"dataset_name\": path,\n",
    "        \"number_of_rows\": table_raw.num_rows\n",
    "    })\n",
    "\n",
    "    fact_metrics.append({\n",
    "        \"dataset_id\": primary_key,\n",
    "        \"extract_time\": round(extract_time, 2),\n",
    "        \"transform_rename_columns_time\": round(transform_rename_columns_time, 2),\n",
    "        \"load_time_csv\": round(load_time_csv, 2),\n",
    "        \"file_size_csv_mb\": file_size_csv,\n",
    "        \"load_time_parquet\": round(load_time_parquet, 2),\n",
    "        \"file_size_parquet_mb\": file_size_parquet,\n",
    "        \"load_time_orc\": round(load_time_orc, 2),\n",
    "        \"file_size_orc_mb\": file_size_orc\n",
    "    })\n",
    "\n",
    "\n",
    "dim_datasets_table = pa.Table.from_pylist(dim_datasets)\n",
    "fact_metrics_table = pa.Table.from_pylist(fact_metrics)\n",
    "\n",
    "csv.write_csv(dim_datasets_table, \"pyarrow_analysis/dim_datasets.csv\")\n",
    "csv.write_csv(fact_metrics_table, \"pyarrow_analysis/fact_metrics_pyarrow.csv\")\n",
    "\n",
    "print(\"Process finished successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
